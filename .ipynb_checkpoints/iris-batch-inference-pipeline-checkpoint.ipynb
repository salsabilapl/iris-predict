{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2kLrOh-bpGy"
   },
   "source": [
    "# Iris Flower - Batch Prediction\n",
    "\n",
    "\n",
    "In this notebook we will, \n",
    "\n",
    "1. Load the batch inference data that arrived in the last 24 hours\n",
    "2. Predict the first Iris Flower found in the batch\n",
    "3. Write the ouput png of the Iris flower predicted, to be displayed in Github Pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xRtpj-psbpG8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/20697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import hopsworks\n",
    "import joblib\n",
    "import os\n",
    "os.environ['CONDA_DLL_SEARCH_MODIFICATION_ENABLE'] = '1' #setting the env variable\n",
    "\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Downloading file ... "
     ]
    }
   ],
   "source": [
    "mr = project.get_model_registry()\n",
    "model = mr.get_model(\"iris_2\", version=1)\n",
    "model_dir = model.download()\n",
    "model = joblib.load(model_dir + \"/iris_2_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are downloading the 'raw' iris data. We explicitly do not want transformed data, reading for training. \n",
    "\n",
    "So, let's download the iris dataset, and preview some rows. \n",
    "\n",
    "Note, that it is 'tabular data'. There are 5 columns: 4 of them are \"features\", and the \"variety\" column is the **target** (what we are trying to predict using the 4 feature values in the target's row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "nRmFM7vcbpHA",
    "outputId": "d920d168-9818-40c5-c292-4cf0afcbbcfd"
   },
   "outputs": [],
   "source": [
    "feature_view = fs.get_feature_view(name=\"iris_2\", version=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do some **Batch Inference**. \n",
    "\n",
    "We will read all the input features that have arrived in the last 24 hours, and score them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uHuAD3ttP8Ep"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: No training dataset version was provided to initialise batch scoring . Defaulting to version 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-19 11:51:16,391 INFO: USE `salsa_coe_featurestore`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-19 11:51:17,251 INFO: SELECT `fg0`.`sepal_length` `sepal_length`, `fg0`.`sepal_width` `sepal_width`, `fg0`.`petal_length` `petal_length`, `fg0`.`petal_width` `petal_width`\n",
      "FROM `salsa_coe_featurestore`.`iris_1` `fg0`\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2092\\4285440280.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_view\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_batch_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from PIL import Image\n",
    "\n",
    "batch_data = feature_view.get_batch_data()\n",
    "\n",
    "y_pred = model.predict(batch_data)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch prediction output is the last entry in the batch - it is output as a file 'latest_iris.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower = y_pred[y_pred.size-1]\n",
    "flower_img = \"assets/\" + flower + \".png\"\n",
    "img = Image.open(flower_img)            \n",
    "\n",
    "img.save(\"../../assets/latest_iris.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_fg = fs.get_feature_group(name=\"iris\", version=1)\n",
    "df = iris_fg.read()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df.iloc[-1][\"variety\"]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_flower = \"assets/\" + label + \".png\"\n",
    "\n",
    "img = Image.open(label_flower)            \n",
    "\n",
    "img.save(\"../../assets/actual_iris.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "monitor_fg = fs.get_or_create_feature_group(name=\"iris_predictions\",\n",
    "                                  version=1,\n",
    "                                  primary_key=[\"datetime\"],\n",
    "                                  description=\"Iris flower Prediction/Outcome Monitoring\"\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "data = {\n",
    "    'prediction': [flower],\n",
    "    'label': [label],\n",
    "    'datetime': [now],\n",
    "}\n",
    "monitor_df = pd.DataFrame(data)\n",
    "monitor_fg.insert(monitor_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = monitor_fg.read()\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataframe_image as dfi\n",
    "\n",
    "df_recent = history_df.tail(5)\n",
    " \n",
    "# If you exclude this image, you may have the same iris_latest.png and iris_actual.png files\n",
    "# If no files have changed, the GH-action 'git commit/push' stage fails, failing your GH action (last step)\n",
    "# This image, however, is always new, ensuring git commit/push will succeed.\n",
    "dfi.export(df_recent, '../../assets/df_recent.png', table_conversion = 'matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = history_df[['prediction']]\n",
    "labels = history_df[['label']]\n",
    "\n",
    "results = confusion_matrix(labels, predictions)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "\n",
    "# Only create the confusion matrix when our iris_predictions feature group has examples of all 3 iris flowers\n",
    "if results.shape == (3,3):\n",
    "\n",
    "    df_cm = pd.DataFrame(results, ['True Setosa', 'True Versicolor', 'True Virginica'],\n",
    "                         ['Pred Setosa', 'Pred Versicolor', 'Pred Virginica'])\n",
    "\n",
    "    cm = sns.heatmap(df_cm, annot=True)\n",
    "\n",
    "    fig = cm.get_figure()\n",
    "    fig.savefig(\"../../assets/confusion_matrix.png\") \n",
    "    df_cm\n",
    "else:\n",
    "    print(\"Run the batch inference pipeline more times until you get 3 different iris flowers\")    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
